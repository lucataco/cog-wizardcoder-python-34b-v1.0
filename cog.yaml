build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "11.8"
  python_version: "3.10"
  python_packages:
    - "torch==2.0.1"
    - "transformers==4.31.0"

  run:
    - "wget https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.0/auto_gptq-0.4.0+cu118-cp310-cp310-linux_x86_64.whl"
    - "pip install auto_gptq-0.4.0+cu118-cp310-cp310-linux_x86_64.whl"

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"